{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Installation & Setup"
      ],
      "metadata": {
        "id": "bvF2LUKURqhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install nltk==3.9.1\n",
        "# !pip install transformers==4.45.2\n",
        "!pip install transformers==4.27.4\n",
        "!pip install datasets==3.0.2\n",
        "!pip install srt==3.5.3\n",
        "!pip install gdown\n",
        "!apt install ffmpeg"
      ],
      "metadata": {
        "id": "MaAi3yOUWxq0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tarfile\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import torch\n",
        "from transformers import LongformerTokenizer, LongformerModel, LongformerForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "import torch.nn.functional as F\n",
        "import gdown\n",
        "import srt"
      ],
      "metadata": {
        "id": "oiFdk6oSYg8w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# NLTK\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('treebank')"
      ],
      "metadata": {
        "id": "uezzF1YfwZ8S",
        "outputId": "8d638f10-a881-420a-ff15-067d38b66fd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Other Dataset: CNN/DailyMail\n",
        "dataset_news = load_dataset(\"cnn_dailymail\", \"3.0.0\")\n",
        "\n",
        "# Dataset\n",
        "folder_id = '1k7DLJPl1xz9lpU4l3dZYtPe1XawhrXeC'\n",
        "gdown.download_folder(id=folder_id, quiet=False, use_cookies=False)\n",
        "\n",
        "path_dataset = \"dataset/\""
      ],
      "metadata": {
        "id": "gd07zZ1sW0Pg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9574468f-113f-4f4c-9ba9-6b4135d0444c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets"
      ],
      "metadata": {
        "id": "0E33VpXsRdq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_dataset = \"dataset/\"\n",
        "filename_video = \"teamwork in the classroom.mov\"\n",
        "filename_subtitles = \"teamwork in the classroom.srt\"\n",
        "\n",
        "# Subtitles:\n",
        "with open(path_dataset + filename_subtitles, \"r\", encoding=\"utf-8\") as f:\n",
        "    subtitles = list(srt.parse(f.read()))\n",
        "\n",
        "# Other: Simple\n",
        "paragrah_simple = \"Renewable energy is crucial for reducing carbon emissions.  \\\n",
        "Solar power, in particular, is sustainable and abundant. Interestingly, \\\n",
        "solar panels were first invented in 1954. With continued advancements, \\\n",
        "solar energy is becoming more accessible in everyday life.\"\n",
        "\n",
        "# Other: CNN/Daily News\n",
        "paragraph_news = dataset_news['train']['article'][0]\n",
        "summary_news = dataset_news['train']['highlights'][0]"
      ],
      "metadata": {
        "id": "KIZL57wtPiYb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SRT\n",
        "each **`subtitle`** in the subtitles array has the following properties:\n",
        "\n",
        "1. **`index`**\n",
        "   - The sequential number of the subtitle within the SRT file.\n",
        "   - `1`, `2`, `3`, etc. (Integer)\n",
        "2. **`start`**\n",
        "   - The time (in milliseconds) when the subtitle should appear on the screen.\n",
        "   - `00:00:05,000` (String representing HH:MM:SS,SSS)\n",
        "3. **`end`**\n",
        "   - The time (in milliseconds) when the subtitle should disappear from the screen.\n",
        "   - `00:00:10,000` (String representing HH:MM:SS,SSS)\n",
        "4. **`content`**\n",
        "   - The actual text of the subtitle that will be displayed.\n",
        "   - \"Hello, world!\" (String)\n",
        "5. **`proprietary`**\n",
        "   - This field holds any additional data or formatting specific to the SRT file or software used to create it. Often empty and can usually be ignored.\n",
        "   - `''` (Empty string, or sometimes contains specific formatting codes)"
      ],
      "metadata": {
        "id": "tCtO9Rg6J5Dz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text: Preprocessing"
      ],
      "metadata": {
        "id": "NqhKyoOO3voB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Intermediate exploration\n",
        "\n",
        "# 'proprietary' field can be safely ignored\"\n",
        "proprietary_values = sum([len(subtitle.proprietary) for subtitle in subtitles])\n",
        "print(proprietary_values) # returns 0"
      ],
      "metadata": {
        "id": "3J6ZYo0UB9kR",
        "outputId": "c51fa796-7bd8-4acb-fbb5-d4db35c24303",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters"
      ],
      "metadata": {
        "id": "AKAOoThoSsgj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Paragraph\n",
        "combination of all subtitle parts."
      ],
      "metadata": {
        "id": "7vSt5ElqS2bK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paragraph\n",
        "paragraph = \" \".join([subtitle.content for subtitle in subtitles])"
      ],
      "metadata": {
        "id": "OFMXfndjQPGs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "KtQPf13i7Ltj",
        "outputId": "71e5b2c8-aaf1-4f0c-e638-55d2f0df76eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"hello this is Leno Kia and today I want to talk to you about a very important topic challenging topic teamwork in the classroom so why is teamwork in the classroom so important well for our students it allows them to develop a bunch of new skills right uh communication skills leadership skills Etc also when you're working with a team you get different perspectives ideally you are part of a team that has uh people with different genders people with uh different a in different age groups people with different academic backgrounds right so when you're talking to them you get all this fresh perspectives that inform your uh the task that you're trying to solve uh also teams will motivate you they will support you you will feel empowered by them ideally right this is like kind the thing that should happen and also this is how the world works right pretty much everything we do we need to do it as a team now here's the thing about teamwork in the classroom students hate it but why do they hate it well these are the things that I can identify they don't know their teammates or or they do know their their teammates but they don't like them uh they're also concerned about an even workload right I'm going to be working all night while this guy is like doing something else uh that is not teamwork and things like that they're also concerned about their grades they're concerned because a lot of it is out of their control right it doesn't matter how hard I work if my teammates are not doing enough work it's going to impact my my own grade and so yeah all of these things are legitimate concerns so what can we do as professors these are the things that I that I do I explain to my students why teamwork is so important I tell them about my own life experiences I am positive but realistic when I talk about teamwork I acknowledge that it's challenging and then once I have created teams it's important to assign class time for team building exercises now if this team is going to work together for 10 minutes every week then maybe you just need a a short uh ice breaker right so that they know each other and they can start working together if you are going to have this team work together for the entire semester it doesn't hurt to use one of your 2hour lectures uh for stronger longer more comprehensive ensive team building exercise and the first time you give your students a task as a team make it a low stake uh task right something that doesn't really impact their grade or if it does it's tiny it's it's minimal and ideally the first time they work together as a team they do this in person working together in person is always uh creates a stronger connection than if you do this virtually now this is the best thing that I have learned about teamwork I had this class and my students were working in teams and after a few weeks I saw that this team was working really well together and so I I approached them and say uh why do you get along so well as a team and their answer was we had dinner together and so this is my advice to every team go and grab a coffee go and you know get lunch together something like that is going to help you connect uh as a team you're going to see everybody as a person and you're going to know each other and yeah it's going to be better trust me now when I create teams uh if it's a short collaboration and by this I mean they're going to be working together about 10 minutes every every class then you can randomly assign them and especially if it's a large class it's going to be a good strategy sometimes especially after they've been they know each other for a month or so you can also let them um you know choose their own teammates and and yeah just pick your team right if it's a long collaboration sometimes self- selection works I have a final project and I tell them you get to pick whoever you you can work with anybody that you want right and so that works but sometimes it's important that you choose a team based on the skills that the team has or based on their interest right so you need to determine when is a good idea for self uh selection or when is a good idea to think of um interest or skills when when created a team depends on the goals of of that uh exercise of that project things like that now the size of the team again this is not what you should do this is what I do right for short collaborations uh usually I create uh four member teams and this is also because of the structure of the classrooms where I work there's the tables with four chairs right uh so makes sense that uh we don't need to disrupt the classroom destroy things uh Move Around furniture too much but if it is a one month or a one semester project I usually create teams of two or three members I find that it's easy to identify what each member has uh has done uh it's easy also for them to for communication purposes and this is what has worked for me but what are your strategies I you know I would love to learn I'm not an expert in team building right I'm just sharing what I've done what has worked for me and what I have learned from my students but I would love to hear your experiences your strategies your uh solutions to this uh teamwork issue and uh yeah please reach out I would love to hear from you thank you so much I am Leno Kia see you next time\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentences\n",
        "Individual sentences from the paragraph.\n",
        "\n",
        "#### Challenges:\n",
        "* Imposing/Detecting punctuation\n",
        "* Incorrect word parsed to transcript"
      ],
      "metadata": {
        "id": "7z5yDt4hToTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Legacy segmentation when sentences were already perfect\n",
        "\n",
        "# Segmentation\n",
        "# sentences_segmented = sent_tokenize(sentences)\n",
        "# print(len(sentences_segmented), '\\n', sentences_segmented)"
      ],
      "metadata": {
        "id": "72E_kMUVUN6b"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.45.2"
      ],
      "metadata": {
        "id": "DGEZb4ctqgt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"universal_dependencies\", \"en_ewt\")"
      ],
      "metadata": {
        "id": "v1Lp2SGnmdSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3 Prepare dataset for token classification\n",
        "def prepare_labels(examples):\n",
        "    labels = []\n",
        "    for sentence in examples[\"tokens\"]:\n",
        "        label = [0] * len(sentence)\n",
        "        label[-1] = 1  # Mark the last token in each sentence as the end of the sentence\n",
        "        labels.append(label)\n",
        "    return {\"tokens\": examples[\"tokens\"], \"labels\": labels}\n",
        "\n",
        "# Apply the function to each split\n",
        "train_dataset = dataset[\"train\"].map(prepare_labels)\n",
        "validation_dataset = dataset[\"validation\"].map(prepare_labels)\n",
        "test_dataset = dataset[\"test\"].map(prepare_labels)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#4 Tokenize and align labels\n",
        "from transformers import RobertaTokenizer\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True, padding=\"max_length\")\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"labels\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        label_ids = []\n",
        "        previous_word_idx = None\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)  # For special tokens\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(-100)  # Only label the first subtoken\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "train_tokenized = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "validation_tokenized = validation_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "test_tokenized = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "\n",
        "#5 Initialize model\n",
        "from transformers import RobertaForTokenClassification\n",
        "\n",
        "model = RobertaForTokenClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
        "\n",
        "#6 set up trainer\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_tokenized,\n",
        "    eval_dataset=validation_tokenized,\n",
        ")\n",
        "\n",
        "# 7 train\n",
        "trainer.train()\n",
        "\n",
        "# 8 Predict\n",
        "def predict_sentence_boundaries(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs).logits\n",
        "    predictions = torch.argmax(outputs, dim=2)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "    result = []\n",
        "    for token, pred in zip(tokens, predictions[0].numpy()):\n",
        "        result.append((token, pred))\n",
        "    return result\n",
        "\n",
        "# Example\n",
        "text = \"This is a sample paragraph Without punctuation It should be split into sentences\"\n",
        "print(predict_sentence_boundaries(text))\n",
        "\n"
      ],
      "metadata": {
        "id": "Vlcec_5hRZwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metric 1: Simple Sentence-Paragraph Relevancy (Cosine Similarity)"
      ],
      "metadata": {
        "id": "_8gMAZOaQKNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# 2: Longformer Model\n",
        "tokenizer_lf = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "model_lf = LongformerModel.from_pretrained('allenai/longformer-base-4096')"
      ],
      "metadata": {
        "id": "kGDOM_LzxmeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3: Tokenization\n",
        "paragraph_tokens = tokenizer_lf(paragraph, return_tensors='pt')\n",
        "sentence_tokens = [tokenizer_lf(sentence, return_tensors='pt') for sentence in sentences_segmented]"
      ],
      "metadata": {
        "id": "c_FszsOCzf02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding Explanation\n",
        "The [CLS] (classification) token is often used in transformer models to represent the overall meaning or summary of the input sequence. By extracting its embedding, you're essentially obtaining a representation that captures the main point or essence of the paragraph."
      ],
      "metadata": {
        "id": "bBHu-QLj6kq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4: Embedding\n",
        "with torch.no_grad(): # Disable gradient computation for efficiency\n",
        "    paragraph_embedding = model_lf(**paragraph_tokens).last_hidden_state[:, 0, :]  # Get the [CLS] token embedding\n",
        "    sentence_embeddings = [model_lf(**tokens).last_hidden_state[:, 0, :] for tokens in sentence_tokens]"
      ],
      "metadata": {
        "id": "7RBG1chM0B8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5: Relevance scores\n",
        "relevance_scores = [torch.cosine_similarity(paragraph_embedding, sentence_embedding).item() for sentence_embedding in sentence_embeddings]\n",
        "\n",
        "\n",
        "temperature = 0.0002\n",
        "relevance_scores_softmax = F.softmax(torch.tensor(relevance_scores)/temperature, dim=0)"
      ],
      "metadata": {
        "id": "9BwrHjKc4Tge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(relevance_scores_softmax * 100)\n",
        "relevance_scores_softmax = relevance_scores_softmax * 100\n",
        "\n",
        "np.set_printoptions(formatter={'float': lambda x: f\"{x:.2g}\"})"
      ],
      "metadata": {
        "id": "WE_FCvp05lX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6: Display Results\n",
        "\n",
        "df = pd.DataFrame({\"Index\": range(len(sentences_segmented)), \"Score\": relevance_scores, \"Sentence\": sentences_segmented })\n",
        "\n",
        "df.sort_values(by=['Score'], ascending=False, inplace=True)\n",
        "\n",
        "display(df)"
      ],
      "metadata": {
        "id": "CNLoAh9FWssQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metric 2: Intra-sentence relevancy\n",
        "Score by if current sentence is needded by adjacent sentences."
      ],
      "metadata": {
        "id": "mtycqPqJfA_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "\n",
        "# Load pre-trained model and tokenizer\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "\n",
        "sentences = sentences_segmented\n",
        "\n",
        "# Store predictions for each sentence\n",
        "predictions = []\n",
        "\n",
        "# Iterate through sentence pairs\n",
        "for i in range(len(sentences) - 1):\n",
        "    sentence1 = sentences[i]\n",
        "    sentence2 = sentences[i + 1]\n",
        "\n",
        "    # Tokenize and prepare input\n",
        "    inputs = tokenizer(sentence1, sentence2, return_tensors='pt', truncation=True, padding=True, add_special_tokens=True)\n",
        "\n",
        "    # Get model prediction\n",
        "    outputs = model(**inputs)\n",
        "    prediction = torch.argmax(outputs.logits).item()\n",
        "\n",
        "    # Store prediction\n",
        "    predictions.append(prediction)\n",
        "\n",
        "# Handle last sentence (no next sentence)\n",
        "predictions.append(0)  # Assume last sentence doesn't need a next sentence"
      ],
      "metadata": {
        "id": "OGX8E0UOaTjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sort_values(by=['Index'], ascending=True, inplace=True)\n",
        "\n",
        "# Add predictions to DataFrame\n",
        "df = df.assign(**{\"Previous Sentence Needed\": predictions})\n",
        "\n",
        "display(df)"
      ],
      "metadata": {
        "id": "XE9fi5WTbSnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio"
      ],
      "metadata": {
        "id": "aJQglUy2Pz3N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading"
      ],
      "metadata": {
        "id": "b-ZAlbXvP1Ye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract audio (wav) from video\n",
        "filename_video = \"teamwork in the classroom.mov\"\n",
        "\n",
        "filename_base = os.path.splitext(filename_video)[0]\n",
        "audio_output = filename_base + \".wav\"\n",
        "\n",
        "filename_input = os.path.join(path_dataset, filename_video)\n",
        "audio_output = os.path.join(path_dataset, audio_output)\n",
        "\n",
        "!ffmpeg -y -i \"$filename_input\" -vn -acodec copy \"$audio_output\"\n",
        "\n",
        "# Download if necessary\n",
        "# from google.colab import files\n",
        "# files.download(os.path.join('/content', audio_output))"
      ],
      "metadata": {
        "id": "_2fZZ7eGPy8S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}