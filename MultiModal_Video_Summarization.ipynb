{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk==3.9.1\n",
        "!pip install transformers==4.45.2"
      ],
      "metadata": {
        "id": "MaAi3yOUWxq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import torch\n",
        "from transformers import LongformerTokenizer, LongformerModel"
      ],
      "metadata": {
        "id": "oiFdk6oSYg8w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "gd07zZ1sW0Pg",
        "outputId": "4d60549b-723d-4e08-c755-5b7bab7b59a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # TVSum Dataset\n",
        "\n",
        "# # Dataset Download: TVSum\n",
        "# !wget -O TVSum.tgz https://people.csail.mit.edu/yalesong/tvsum/tvsum50_ver_1_1.tgz\n",
        "\n",
        "# # Extract the dataset\n",
        "# with tarfile.open(\"TVSum.tgz\", 'r:gz') as tar_ref:\n",
        "#     tar_ref.extractall(\"./\")\n",
        "\n",
        "\n",
        "# !ls ydata-tvsum50-v1_1\n",
        "\n",
        "# # Path to the extracted dataset (adjust if needed)\n",
        "# dataset_path = \"ydata-tvsum50-v1_1\"\n",
        "\n",
        "# # Example: List the video files in the dataset\n",
        "# video_files = [f for f in os.listdir(dataset_path) ]\n",
        "# # video_files = [f for f in os.listdir(dataset_path) if f.endswith(\".mp4\")]\n",
        "# print(\"Video files found:\", video_files)"
      ],
      "metadata": {
        "id": "v4xt1TKsYf-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text"
      ],
      "metadata": {
        "id": "NqhKyoOO3voB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1: Text Processing - Segmentation\n",
        "paragraph = \"Renewable energy is crucial for reducing carbon emissions. Solar power, in particular, is sustainable and abundant. Interestingly, solar panels were first invented in 1954. With continued advancements, solar energy is becoming more accessible in everyday life.\"\n",
        "sentences = sent_tokenize(paragraph)\n",
        "print(len(sentences), '\\n', sentences)"
      ],
      "metadata": {
        "id": "MnUUgHmMWl9v",
        "outputId": "b129d3d6-9ab4-4296-c760-20ecceacee26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 \n",
            " ['Renewable energy is crucial for reducing carbon emissions.', 'Solar power, in particular, is sustainable and abundant.', 'Interestingly, solar panels were first invented in 1954.', 'With continued advancements, solar energy is becoming more accessible in everyday life.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2: Longformer Model\n",
        "tokenizer_lf = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "model_lf = LongformerModel.from_pretrained('allenai/longformer-base-4096')"
      ],
      "metadata": {
        "id": "kGDOM_LzxmeM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3: Tokenization\n",
        "paragraph_tokens = tokenizer_lf(paragraph, return_tensors='pt')\n",
        "sentence_tokens = [tokenizer_lf(sentence, return_tensors='pt') for sentence in sentences]"
      ],
      "metadata": {
        "id": "c_FszsOCzf02"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4: Embedding\n",
        "with torch.no_grad(): # Disable gradient computation for efficiency\n",
        "    paragraph_embedding = model_lf(**paragraph_tokens).last_hidden_state[:, 0, :]  # Get the [CLS] token embedding\n",
        "    sentence_embeddings = [model_lf(**tokens).last_hidden_state[:, 0, :] for tokens in sentence_tokens]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RBG1chM0B8x",
        "outputId": "e55a1cc0-21f2-4637-d00c-c30d747546be"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Input ids are automatically padded to be a multiple of `config.attention_window`: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The [CLS] (classification) token is often used in transformer models to represent the overall meaning or summary of the input sequence. By extracting its embedding, you're essentially obtaining a representation that captures the main point or essence of the paragraph."
      ],
      "metadata": {
        "id": "bBHu-QLj6kq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5: Relevance scores\n",
        "relevance_scores = [torch.cosine_similarity(paragraph_embedding, sentence_embedding).item() for sentence_embedding in sentence_embeddings]"
      ],
      "metadata": {
        "id": "9BwrHjKc4Tge"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(relevance_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE_FCvp05lX8",
        "outputId": "cb4f6c4c-f6c4-4136-eb4b-f264432c8d17"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9989673495292664, 0.9986081719398499, 0.9978553056716919, 0.9988285303115845]\n"
          ]
        }
      ]
    }
  ]
}